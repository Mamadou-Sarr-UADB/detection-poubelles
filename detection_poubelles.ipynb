{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07a3763",
   "metadata": {},
   "source": [
    "# ğŸ—‘ï¸ DÃ©tection et Classification de Poubelles avec YOLO\n",
    "\n",
    "Ce notebook implÃ©mente un systÃ¨me complet de dÃ©tection et classification de poubelles en utilisant **uniquement YOLOv8** :\n",
    "- **YOLOv8** : DÃ©tection des poubelles ET classification (plein/vide) en une seule Ã©tape\n",
    "\n",
    "Plus simple, plus rapide et plus efficace qu'utiliser deux modÃ¨les sÃ©parÃ©s !\n",
    "Toutes les fonctions sont en franÃ§ais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb38adc",
   "metadata": {},
   "source": [
    "## 1. Installation et Importation des BibliothÃ¨ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f8327f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (8.3.230)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: pillow in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (6.0.3)\n",
      "Requirement already satisfied: roboflow in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (1.2.11)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from ultralytics) (2.9.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from ultralytics) (0.24.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from ultralytics) (7.1.0)\n",
      "Requirement already satisfied: polars>=0.20.0 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from ultralytics) (1.35.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from roboflow) (2025.10.5)\n",
      "Requirement already satisfied: idna==3.7 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: pi-heif<2 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from roboflow) (1.1.1)\n",
      "Requirement already satisfied: pillow-avif-plugin<2 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from roboflow) (1.5.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from roboflow) (1.2.1)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from roboflow) (2.5.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from polars>=0.20.0->ultralytics) (1.35.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\miniconda3\\envs\\tf310\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installation des bibliothÃ¨ques nÃ©cessaires\n",
    "%pip install --user ultralytics opencv-python pillow matplotlib numpy pandas pyyaml roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c11fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ BibliothÃ¨ques importÃ©es avec succÃ¨s!\n"
     ]
    }
   ],
   "source": [
    "# Importation des bibliothÃ¨ques\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "print(\"âœ“ BibliothÃ¨ques importÃ©es avec succÃ¨s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c7a70f",
   "metadata": {},
   "source": [
    "## 2. Configuration du Projet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d7a39",
   "metadata": {},
   "source": [
    "## 3. TÃ©lÃ©chargement du Dataset depuis Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e029829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Configuration chargÃ©e\n",
      "ğŸ“Š Dataset sera tÃ©lÃ©chargÃ© depuis Roboflow\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Chemins (seront mis Ã  jour aprÃ¨s tÃ©lÃ©chargement Roboflow)\n",
    "    'dossier_dataset': '',  # Sera rempli par Roboflow\n",
    "    'yaml_path': '',         # Sera rempli par Roboflow\n",
    "    'poids_yolo': 'models/yolo_poubelles.pt',\n",
    "    'dossier_resultats': 'results',\n",
    "    \n",
    "    # ParamÃ¨tres YOLO\n",
    "    'modele_base': 'yolov8n.pt',  # n=nano (rapide), s=small, m=medium, l=large\n",
    "    'taille_image': 640,\n",
    "    'epochs': 30,\n",
    "    'batch_size': 16,\n",
    "    'confiance': 0.5,\n",
    "    'iou': 0.45,\n",
    "    \n",
    "    # Roboflow\n",
    "    'roboflow_api_key': '4zGCDGgIjB5Lg8TVVqSY',\n",
    "    'roboflow_workspace': 'deep-nhhm8',\n",
    "    'roboflow_project': 'my-first-project-prs1r',\n",
    "    'roboflow_version': 2\n",
    "}\n",
    "\n",
    "print(\"âœ“ Configuration chargÃ©e\")\n",
    "print(\"ğŸ“Š Dataset sera tÃ©lÃ©chargÃ© depuis Roboflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99146972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ TÃ©lÃ©chargement du dataset depuis Roboflow...\n",
      "======================================================================\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "loading Roboflow project...\n",
      "\n",
      "âœ“ Dataset tÃ©lÃ©chargÃ© dans: c:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2\n",
      "âœ“ Fichier data.yaml: c:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2/data.yaml\n",
      "\n",
      "ğŸ“Š Informations du dataset:\n",
      "  - Localisation: c:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2\n",
      "  - Format: YOLOv9/YOLOv8\n",
      "======================================================================\n",
      "\n",
      "âœ“ Dataset tÃ©lÃ©chargÃ© dans: c:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2\n",
      "âœ“ Fichier data.yaml: c:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2/data.yaml\n",
      "\n",
      "ğŸ“Š Informations du dataset:\n",
      "  - Localisation: c:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2\n",
      "  - Format: YOLOv9/YOLOv8\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "def telecharger_dataset_roboflow():\n",
    "    \"\"\"\n",
    "    TÃ©lÃ©charge le dataset depuis Roboflow\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“¥ TÃ©lÃ©chargement du dataset depuis Roboflow...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialiser Roboflow avec les paramÃ¨tres du CONFIG\n",
    "    rf = Roboflow(api_key=CONFIG['roboflow_api_key'])\n",
    "    project = rf.workspace(CONFIG['roboflow_workspace']).project(CONFIG['roboflow_project'])\n",
    "    version = project.version(CONFIG['roboflow_version'])\n",
    "    \n",
    "    # TÃ©lÃ©charger au format YOLOv9 (compatible avec YOLOv8)\n",
    "    dataset = version.download(\"yolov9\")\n",
    "    \n",
    "    print(f\"\\nâœ“ Dataset tÃ©lÃ©chargÃ© dans: {dataset.location}\")\n",
    "    print(f\"âœ“ Fichier data.yaml: {dataset.location}/data.yaml\")\n",
    "    \n",
    "    # Mettre Ã  jour la configuration\n",
    "    CONFIG['dossier_dataset'] = dataset.location\n",
    "    CONFIG['yaml_path'] = f\"{dataset.location}/data.yaml\"\n",
    "    \n",
    "    print(\"\\nğŸ“Š Informations du dataset:\")\n",
    "    print(f\"  - Localisation: {dataset.location}\")\n",
    "    print(f\"  - Format: YOLOv9/YOLOv8\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "# TÃ©lÃ©charger le dataset\n",
    "dataset = telecharger_dataset_roboflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173c43d9",
   "metadata": {},
   "source": [
    "## 4. VÃ©rification du Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2199c3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” VÃ©rification du dataset...\n",
      "======================================================================\n",
      "âœ“ Fichier data.yaml trouvÃ©: c:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2\\data.yaml\n",
      "\n",
      "ğŸ“Š Contenu du data.yaml:\n",
      "  - Nombre de classes: 2\n",
      "  - Classes: ['poubelle_pleine', 'poubelle_vide']\n",
      "  - Train: ../train/images\n",
      "  - Val: ../valid/images\n",
      "  - Test: ../test/images\n",
      "\n",
      "ğŸ“ Statistiques du dataset:\n",
      "  - Images d'entraÃ®nement: 345\n",
      "  - Images de validation: 0\n",
      "  - Images de test: 25\n",
      "  - Total: 370\n",
      "======================================================================\n",
      "âœ“ Dataset prÃªt pour l'entraÃ®nement!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def verifier_dataset():\n",
    "    \"\"\"\n",
    "    VÃ©rifie que le dataset Roboflow est bien tÃ©lÃ©chargÃ© et configurÃ©\n",
    "    \"\"\"\n",
    "    if not CONFIG['dossier_dataset']:\n",
    "        print(\"âŒ Dataset non tÃ©lÃ©chargÃ©. ExÃ©cutez d'abord la cellule de tÃ©lÃ©chargement Roboflow!\")\n",
    "        return False\n",
    "    \n",
    "    dataset_path = Path(CONFIG['dossier_dataset'])\n",
    "    yaml_path = Path(CONFIG['yaml_path'])\n",
    "    \n",
    "    print(\"ğŸ” VÃ©rification du dataset...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # VÃ©rifier le fichier YAML\n",
    "    if yaml_path.exists():\n",
    "        print(f\"âœ“ Fichier data.yaml trouvÃ©: {yaml_path}\")\n",
    "        \n",
    "        # Lire le contenu\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "            print(f\"\\nğŸ“Š Contenu du data.yaml:\")\n",
    "            print(f\"  - Nombre de classes: {data.get('nc', 'N/A')}\")\n",
    "            print(f\"  - Classes: {data.get('names', 'N/A')}\")\n",
    "            print(f\"  - Train: {data.get('train', 'N/A')}\")\n",
    "            print(f\"  - Val: {data.get('val', 'N/A')}\")\n",
    "            if 'test' in data:\n",
    "                print(f\"  - Test: {data.get('test', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"âŒ Fichier data.yaml non trouvÃ©: {yaml_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Compter les images\n",
    "    train_images = list(dataset_path.glob('**/train/images/*.*'))\n",
    "    val_images = list(dataset_path.glob('**/val/images/*.*'))\n",
    "    test_images = list(dataset_path.glob('**/test/images/*.*'))\n",
    "    \n",
    "    print(f\"\\nğŸ“ Statistiques du dataset:\")\n",
    "    print(f\"  - Images d'entraÃ®nement: {len(train_images)}\")\n",
    "    print(f\"  - Images de validation: {len(val_images)}\")\n",
    "    print(f\"  - Images de test: {len(test_images)}\")\n",
    "    print(f\"  - Total: {len(train_images) + len(val_images) + len(test_images)}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"âœ“ Dataset prÃªt pour l'entraÃ®nement!\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# VÃ©rifier le dataset (dÃ©commentez aprÃ¨s avoir tÃ©lÃ©chargÃ©)\n",
    "verifier_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a0fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” VÃ©rification du dataset...\n",
      "======================================================================\n",
      "âœ“ Fichier data.yaml trouvÃ©: c:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2\\data.yaml\n",
      "\n",
      "ğŸ“Š Contenu du data.yaml:\n",
      "  - Nombre de classes: 2\n",
      "  - Classes: ['poubelle_pleine', 'poubelle_vide']\n",
      "  - Train: ../train/images\n",
      "  - Val: ../valid/images\n",
      "  - Test: ../test/images\n",
      "\n",
      "ğŸ“ Statistiques du dataset:\n",
      "  - Images d'entraÃ®nement: 345\n",
      "  - Images de validation: 0\n",
      "  - Images de test: 25\n",
      "  - Total: 370\n",
      "======================================================================\n",
      "âœ“ Dataset prÃªt pour l'entraÃ®nement!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appeler la vÃ©rification\n",
    "verifier_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fd7487",
   "metadata": {},
   "source": [
    "## 5. EntraÃ®nement du ModÃ¨le YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "157fb5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ENTRAÃNEMENT YOLO\n",
      "Dataset: Roboflow\n",
      "DÃ©tection + Classification en une seule Ã©tape\n",
      "======================================================================\n",
      "\n",
      "âœ“ ModÃ¨le yolov8n.pt chargÃ©\n",
      "âœ“ Dataset YAML: c:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2/data.yaml\n",
      "\n",
      "DÃ©but de l'entraÃ®nement...\n",
      "\n",
      "Ultralytics 8.3.230  Python-3.10.18 torch-2.9.1+cpu CPU (11th Gen Intel Core i7-1165G7 @ 2.80GHz)\n",
      "Ultralytics 8.3.230  Python-3.10.18 torch-2.9.1+cpu CPU (11th Gen Intel Core i7-1165G7 @ 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=c:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection_classification_poubelles2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\runs\\detect\\detection_classification_poubelles2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=c:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection_classification_poubelles2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\runs\\detect\\detection_classification_poubelles2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 576.2253.8 MB/s, size: 41.6 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 576.2253.8 MB/s, size: 41.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2\\train\\labels.cache... 345 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 345/345 344.9Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 356.3110.0 MB/s, size: 31.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2\\train\\labels.cache... 345 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 345/345 344.9Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 356.3110.0 MB/s, size: 31.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2\\valid\\labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 25.0Kit/s 0.0s\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\My-First-Project-2\\valid\\labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 25.0Kit/s 0.0s\n",
      "Plotting labels to C:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\runs\\detect\\detection_classification_poubelles2\\labels.jpg... \n",
      "Plotting labels to C:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\runs\\detect\\detection_classification_poubelles2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\runs\\detect\\detection_classification_poubelles2\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\Dell\\Documents\\DEEP LEARNING\\Nouveau dossier\\runs\\detect\\detection_classification_poubelles2\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30         0G      1.433      2.788       1.81         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 5.6s/it 2:034.6ss\n",
      "\u001b[K       1/30         0G      1.433      2.788       1.81         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 5.6s/it 2:034.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5s/it 3.5s\n",
      "                   all         25         36    0.00422      0.907      0.422      0.136\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5s/it 3.5s\n",
      "                   all         25         36    0.00422      0.907      0.422      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30         0G      1.428      2.351      1.779         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 5.9s/it 2:095.0ss\n",
      "\u001b[K       2/30         0G      1.428      2.351      1.779         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 5.9s/it 2:095.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6s/it 3.6s\n",
      "                   all         25         36      0.363      0.321      0.292      0.114\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6s/it 3.6s\n",
      "                   all         25         36      0.363      0.321      0.292      0.114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30         0G      1.497      2.321      1.825         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.0s/it 2:135.1ss\n",
      "\u001b[K       3/30         0G      1.497      2.321      1.825         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.0s/it 2:135.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8s/it 3.8s\n",
      "                   all         25         36      0.316      0.257      0.377      0.157\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8s/it 3.8s\n",
      "                   all         25         36      0.316      0.257      0.377      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30         0G      1.549      2.248      1.816         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.5s/it 2:226.8ss\n",
      "\u001b[K       4/30         0G      1.549      2.248      1.816         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.5s/it 2:226.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.8s/it 5.8s\n",
      "                   all         25         36      0.163      0.278      0.171     0.0653\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.8s/it 5.8s\n",
      "                   all         25         36      0.163      0.278      0.171     0.0653\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30         0G      1.549      2.159      1.814         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 7.6s/it 2:486.1ss\n",
      "\u001b[K       5/30         0G      1.549      2.159      1.814         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 7.6s/it 2:486.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1s/it 4.1s\n",
      "                   all         25         36        0.2      0.426      0.202     0.0762\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1s/it 4.1s\n",
      "                   all         25         36        0.2      0.426      0.202     0.0762\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30         0G       1.46      2.051       1.78         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 7.2s/it 2:386.0ss\n",
      "\u001b[K       6/30         0G       1.46      2.051       1.78         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 7.2s/it 2:386.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1s/it 4.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1s/it 4.1s\n",
      "                   all         25         36       0.57      0.167     0.0632     0.0217\n",
      "                   all         25         36       0.57      0.167     0.0632     0.0217\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30         0G      1.462      1.945      1.734         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.9s/it 2:326.0ss\n",
      "\u001b[K       7/30         0G      1.462      1.945      1.734         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.9s/it 2:326.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8s/it 3.8s\n",
      "                   all         25         36      0.609      0.241      0.285      0.123\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8s/it 3.8s\n",
      "                   all         25         36      0.609      0.241      0.285      0.123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30         0G      1.436      1.841      1.685         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.8s/it 2:295.7ss\n",
      "\u001b[K       8/30         0G      1.436      1.841      1.685         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.8s/it 2:295.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9s/it 3.9s\n",
      "                   all         25         36       0.31      0.594      0.283      0.105\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9s/it 3.9s\n",
      "                   all         25         36       0.31      0.594      0.283      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30         0G      1.424      1.896      1.721         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.5s/it 2:245.7ss\n",
      "\u001b[K       9/30         0G      1.424      1.896      1.721         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.5s/it 2:245.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8s/it 3.8s\n",
      "                   all         25         36      0.407      0.566      0.492      0.226\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8s/it 3.8s\n",
      "                   all         25         36      0.407      0.566      0.492      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30         0G      1.419       1.78      1.712         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.8s/it 2:305.7ss\n",
      "\u001b[K      10/30         0G      1.419       1.78      1.712         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 6.8s/it 2:305.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.5s/it 4.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.5s/it 4.5s\n",
      "                   all         25         36      0.491       0.63      0.536      0.233\n",
      "                   all         25         36      0.491       0.63      0.536      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30         0G      1.386      1.709      1.661         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 7.2s/it 2:386.6ss\n",
      "\u001b[K      11/30         0G      1.386      1.709      1.661         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 22/22 7.2s/it 2:386.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.5s/it 4.5s\n",
      "                   all         25         36      0.389      0.593      0.374      0.187\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.5s/it 4.5s\n",
      "                   all         25         36      0.389      0.593      0.374      0.187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30         0G      1.426      1.703      1.702         58        640: 36% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 8/22 7.6s/it 1:09<1:4617\n",
      "\u001b[K      12/30         0G      1.426      1.703      1.702         58        640: 36% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 8/22 7.6s/it 1:09<1:46\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 54\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m modele\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Note: DÃ©commentez pour lancer l'entraÃ®nement aprÃ¨s avoir tÃ©lÃ©chargÃ© le dataset\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m modele_yolo \u001b[38;5;241m=\u001b[39m \u001b[43mentrainer_yolo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 24\u001b[0m, in \u001b[0;36mentrainer_yolo\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDÃ©but de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentraÃ®nement...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# EntraÃ®ner le modÃ¨le\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m resultats \u001b[38;5;241m=\u001b[39m \u001b[43mmodele\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myaml_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtaille_image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdetection_classification_poubelles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mruns/detect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 'cpu' car pas de GPU disponible\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ“ ENTRAÃNEMENT TERMINÃ‰!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Miniconda3\\envs\\tf310\\lib\\site-packages\\ultralytics\\engine\\model.py:778\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m--> 778\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Miniconda3\\envs\\tf310\\lib\\site-packages\\ultralytics\\engine\\trainer.py:243\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 243\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Miniconda3\\envs\\tf310\\lib\\site-packages\\ultralytics\\engine\\trainer.py:434\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_step()\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Miniconda3\\envs\\tf310\\lib\\site-packages\\torch\\_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    624\u001b[0m     )\n\u001b[1;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Miniconda3\\envs\\tf310\\lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Miniconda3\\envs\\tf310\\lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    842\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    843\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def entrainer_yolo():\n",
    "    \"\"\"\n",
    "    EntraÃ®ne YOLOv8 sur le dataset Roboflow\n",
    "    DÃ©tection + Classification en une seule Ã©tape !\n",
    "    \"\"\"\n",
    "    if not CONFIG['yaml_path']:\n",
    "        print(\"âŒ Erreur: TÃ©lÃ©chargez d'abord le dataset depuis Roboflow!\")\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ENTRAÃNEMENT YOLO\")\n",
    "    print(\"Dataset: Roboflow\")\n",
    "    print(\"DÃ©tection + Classification en une seule Ã©tape\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Charger le modÃ¨le de base prÃ©-entraÃ®nÃ©\n",
    "    modele = YOLO(CONFIG['modele_base'])\n",
    "    \n",
    "    print(f\"âœ“ ModÃ¨le {CONFIG['modele_base']} chargÃ©\")\n",
    "    print(f\"âœ“ Dataset YAML: {CONFIG['yaml_path']}\")\n",
    "    print(f\"\\nDÃ©but de l'entraÃ®nement...\\n\")\n",
    "    \n",
    "    # EntraÃ®ner le modÃ¨le\n",
    "    resultats = modele.train(\n",
    "        data=CONFIG['yaml_path'],\n",
    "        epochs=CONFIG['epochs'],\n",
    "        imgsz=CONFIG['taille_image'],\n",
    "        batch=CONFIG['batch_size'],\n",
    "        name='detection_classification_poubelles',\n",
    "        project='runs/detect',\n",
    "        patience=15,\n",
    "        save=True,\n",
    "        plots=True,\n",
    "        verbose=True,\n",
    "        device='cpu'  # 'cpu' car pas de GPU disponible\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ“ ENTRAÃNEMENT TERMINÃ‰!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Sauvegarder le meilleur modÃ¨le\n",
    "    chemin_best = Path('runs/detect/detection_classification_poubelles/weights/best.pt')\n",
    "    if chemin_best.exists():\n",
    "        import shutil\n",
    "        Path(CONFIG['poids_yolo']).parent.mkdir(exist_ok=True, parents=True)\n",
    "        shutil.copy(chemin_best, CONFIG['poids_yolo'])\n",
    "        print(f\"\\nâœ“ Meilleur modÃ¨le sauvegardÃ©: {CONFIG['poids_yolo']}\")\n",
    "    \n",
    "    return modele\n",
    "\n",
    "\n",
    "# Note: DÃ©commentez pour lancer l'entraÃ®nement aprÃ¨s avoir tÃ©lÃ©chargÃ© le dataset\n",
    "modele_yolo = entrainer_yolo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640bc3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ModÃ¨le chargÃ© avec succÃ¨s : models/yolo_poubelles.pt\n",
      "Classes du modÃ¨le : {0: 'poubelle_pleine', 1: 'poubelle_vide'}\n"
     ]
    }
   ],
   "source": [
    "# Charger votre modÃ¨le entraÃ®nÃ© depuis Google Colab\n",
    "import os\n",
    "\n",
    "# VÃ©rifier si le modÃ¨le existe\n",
    "if os.path.exists(CONFIG['poids_yolo']):\n",
    "    modele = YOLO(CONFIG['poids_yolo'])\n",
    "    print(f\"âœ… ModÃ¨le chargÃ© avec succÃ¨s : {CONFIG['poids_yolo']}\")\n",
    "    print(f\"Classes du modÃ¨le : {modele.names}\")\n",
    "else:\n",
    "    print(f\"âŒ ModÃ¨le non trouvÃ© : {CONFIG['poids_yolo']}\")\n",
    "    print(\"\\nğŸ“‹ Instructions :\")\n",
    "    print(\"1. Copiez le fichier 'best.pt' depuis Google Colab\")\n",
    "    print(\"2. CrÃ©ez le dossier 'models/' si nÃ©cessaire\")\n",
    "    print(\"3. Placez le fichier dans 'models/yolo_poubelles.pt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65614720",
   "metadata": {},
   "source": [
    "### ğŸ“¥ Charger le modÃ¨le dÃ©jÃ  entraÃ®nÃ©\n",
    "\n",
    "Si vous avez dÃ©jÃ  entraÃ®nÃ© le modÃ¨le sur Google Colab :\n",
    "1. Placez le fichier `best.pt` dans le dossier `models/` \n",
    "2. Renommez-le en `yolo_poubelles.pt`\n",
    "3. ExÃ©cutez la cellule suivante pour charger le modÃ¨le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60165d45",
   "metadata": {},
   "source": [
    "## 6. Validation du ModÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b707338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valider_modele():\n",
    "    \"\"\"\n",
    "    Valide le modÃ¨le YOLO sur les donnÃ©es de test\n",
    "    \"\"\"\n",
    "    chemin_modele = CONFIG['poids_yolo']\n",
    "    \n",
    "    if not Path(chemin_modele).exists():\n",
    "        print(f\"âŒ ModÃ¨le non trouvÃ©: {chemin_modele}\")\n",
    "        print(\"EntraÃ®nez d'abord le modÃ¨le!\")\n",
    "        return None\n",
    "    \n",
    "    if not CONFIG['yaml_path']:\n",
    "        print(\"âŒ Erreur: Chemin du dataset YAML non configurÃ©!\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Chargement du modÃ¨le...\")\n",
    "    modele = YOLO(chemin_modele)\n",
    "    \n",
    "    print(\"Validation en cours...\\n\")\n",
    "    \n",
    "    # Valider sur le dataset\n",
    "    resultats = modele.val(\n",
    "        data=CONFIG['yaml_path'],\n",
    "        split='test'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“Š RÃ‰SULTATS DE VALIDATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"mAP50: {resultats.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {resultats.box.map:.4f}\")\n",
    "    print(f\"PrÃ©cision: {resultats.box.mp:.4f}\")\n",
    "    print(f\"Rappel: {resultats.box.mr:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return resultats\n",
    "\n",
    "\n",
    "# Note: DÃ©commentez aprÃ¨s l'entraÃ®nement\n",
    "# resultats_validation = valider_modele()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e2616",
   "metadata": {},
   "source": [
    "## 7. DÃ©tection et Classification sur Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e859134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charger_modele_entraine():\n",
    "    \"\"\"\n",
    "    Charge le modÃ¨le YOLO entraÃ®nÃ©\n",
    "    \"\"\"\n",
    "    chemin_modele = CONFIG['poids_yolo']\n",
    "    \n",
    "    if not Path(chemin_modele).exists():\n",
    "        print(f\"âš ï¸ ModÃ¨le personnalisÃ© non trouvÃ©\")\n",
    "        print(f\"Utilisation du modÃ¨le de base: {CONFIG['modele_base']}\")\n",
    "        return YOLO(CONFIG['modele_base'])\n",
    "    \n",
    "    modele = YOLO(chemin_modele)\n",
    "    print(f\"âœ“ ModÃ¨le chargÃ©: {chemin_modele}\")\n",
    "    return modele\n",
    "\n",
    "\n",
    "def detecter_et_classifier(image_path, modele, seuil_confiance=0.5):\n",
    "    \"\"\"\n",
    "    DÃ©tecte et classifie les poubelles en une seule Ã©tape avec YOLO\n",
    "    \n",
    "    Args:\n",
    "        image_path: Chemin vers l'image\n",
    "        modele: ModÃ¨le YOLO\n",
    "        seuil_confiance: Seuil de confiance minimum\n",
    "    \n",
    "    Returns:\n",
    "        image_resultat: Image annotÃ©e\n",
    "        detections: Liste des dÃ©tections avec classes\n",
    "    \"\"\"\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        print(f\"âŒ Erreur: Impossible de charger {image_path}\")\n",
    "        return None, []\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # PrÃ©diction avec YOLO (dÃ©tection + classification)\n",
    "    resultats = modele(image, conf=seuil_confiance, verbose=False)\n",
    "    \n",
    "    detections = []\n",
    "    \n",
    "    for resultat in resultats:\n",
    "        boxes = resultat.boxes\n",
    "        \n",
    "        for box in boxes:\n",
    "            # Extraire les informations\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "            confiance = float(box.conf[0].cpu().numpy())\n",
    "            classe_id = int(box.cls[0].cpu().numpy())\n",
    "            nom_classe = modele.names[classe_id]\n",
    "            \n",
    "            # DÃ©terminer l'Ã©tat (vide ou plein)\n",
    "            etat = 'vide' if 'vide' in nom_classe.lower() or 'empty' in nom_classe.lower() else 'plein'\n",
    "            \n",
    "            # Stocker la dÃ©tection\n",
    "            detections.append({\n",
    "                'bbox': (x1, y1, x2, y2),\n",
    "                'confiance': confiance,\n",
    "                'classe': nom_classe,\n",
    "                'etat': etat\n",
    "            })\n",
    "            \n",
    "            # Dessiner sur l'image\n",
    "            couleur = (0, 255, 0) if etat == 'vide' else (255, 0, 0)\n",
    "            cv2.rectangle(image_rgb, (x1, y1), (x2, y2), couleur, 3)\n",
    "            \n",
    "            # Texte\n",
    "            texte = f\"{etat.upper()} ({confiance:.2f})\"\n",
    "            \n",
    "            # Fond pour le texte\n",
    "            (text_width, text_height), _ = cv2.getTextSize(\n",
    "                texte, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2\n",
    "            )\n",
    "            cv2.rectangle(\n",
    "                image_rgb, \n",
    "                (x1, y1 - text_height - 10), \n",
    "                (x1 + text_width, y1), \n",
    "                couleur, \n",
    "                -1\n",
    "            )\n",
    "            \n",
    "            cv2.putText(\n",
    "                image_rgb, texte, (x1, y1-5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2\n",
    "            )\n",
    "    \n",
    "    return image_rgb, detections\n",
    "\n",
    "\n",
    "def afficher_resultats(image_resultat, detections):\n",
    "    \"\"\"\n",
    "    Affiche les rÃ©sultats de dÃ©tection et classification\n",
    "    \"\"\"\n",
    "    if image_resultat is None:\n",
    "        return\n",
    "    \n",
    "    # Afficher l'image\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image_resultat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'DÃ©tections: {len(detections)} poubelle(s)', \n",
    "              fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Afficher les dÃ©tails\n",
    "    if len(detections) == 0:\n",
    "        print(\"\\nâš ï¸ Aucune poubelle dÃ©tectÃ©e\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“Š RÃ‰SULTATS DE DÃ‰TECTION ET CLASSIFICATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, det in enumerate(detections, 1):\n",
    "        icone = 'âœ…' if det['etat'] == 'vide' else 'ğŸ”´'\n",
    "        print(f\"\\nPoubelle {i}:\")\n",
    "        print(f\"  {icone} Ã‰tat: {det['etat'].upper()}\")\n",
    "        print(f\"  ğŸ“ Confiance: {det['confiance']:.1%}\")\n",
    "        print(f\"  ğŸ“¦ Position: {det['bbox']}\")\n",
    "    \n",
    "    # Statistiques\n",
    "    nb_vides = sum(1 for d in detections if d['etat'] == 'vide')\n",
    "    nb_pleines = sum(1 for d in detections if d['etat'] == 'plein')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“ˆ STATISTIQUES\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"  Total: {len(detections)} poubelle(s)\")\n",
    "    print(f\"  Vides: {nb_vides}\")\n",
    "    print(f\"  Pleines: {nb_pleines}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# modele = charger_modele_entraine()\n",
    "# image_resultat, detections = detecter_et_classifier('chemin/vers/image.jpg', modele)\n",
    "# afficher_resultats(image_resultat, detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b7717",
   "metadata": {},
   "source": [
    "## 8. DÃ©tection sur VidÃ©o ou Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detecter_video(source, modele, afficher=True, sauvegarder=False, chemin_sortie='output.mp4'):\n",
    "    \"\"\"\n",
    "    DÃ©tecte et classifie les poubelles dans une vidÃ©o ou webcam\n",
    "    \n",
    "    Args:\n",
    "        source: Chemin de la vidÃ©o ou 0 pour webcam\n",
    "        modele: ModÃ¨le YOLO\n",
    "        afficher: Afficher la vidÃ©o en temps rÃ©el\n",
    "        sauvegarder: Sauvegarder la vidÃ©o annotÃ©e\n",
    "        chemin_sortie: Chemin de sauvegarde\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"âŒ Erreur: Impossible d'ouvrir {source}\")\n",
    "        return\n",
    "    \n",
    "    # Configuration pour la sauvegarde\n",
    "    if sauvegarder:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        out = cv2.VideoWriter(chemin_sortie, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(\"ğŸ“¹ Traitement vidÃ©o en cours...\")\n",
    "    print(\"Appuyez sur 'q' pour quitter\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # DÃ©tection avec YOLO\n",
    "        resultats = modele(frame, conf=CONFIG['confiance'], verbose=False)\n",
    "        \n",
    "        # Annoter le frame\n",
    "        frame_annote = resultats[0].plot()\n",
    "        \n",
    "        # Afficher\n",
    "        if afficher:\n",
    "            cv2.imshow('DÃ©tection Poubelles', frame_annote)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # Sauvegarder\n",
    "        if sauvegarder:\n",
    "            out.write(frame_annote)\n",
    "        \n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"  Frame {frame_count} traitÃ©...\")\n",
    "    \n",
    "    cap.release()\n",
    "    if sauvegarder:\n",
    "        out.release()\n",
    "        print(f\"\\nâœ“ VidÃ©o sauvegardÃ©e: {chemin_sortie}\")\n",
    "    \n",
    "    if afficher:\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"\\nâœ“ {frame_count} frames traitÃ©s\")\n",
    "\n",
    "\n",
    "# Exemples d'utilisation\n",
    "# modele = charger_modele_entraine()\n",
    "\n",
    "# Webcam\n",
    "# detecter_video(0, modele)\n",
    "\n",
    "# VidÃ©o\n",
    "# detecter_video('chemin/vers/video.mp4', modele, sauvegarder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6182b491",
   "metadata": {},
   "source": [
    "## 9. DÃ©tection sur Multiple Images (Batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detecter_dossier(dossier_images, modele, sauvegarder=True):\n",
    "    \"\"\"\n",
    "    DÃ©tecte et classifie les poubelles pour toutes les images d'un dossier\n",
    "    \n",
    "    Args:\n",
    "        dossier_images: Chemin du dossier contenant les images\n",
    "        modele: ModÃ¨le YOLO\n",
    "        sauvegarder: Sauvegarder les images annotÃ©es\n",
    "    \"\"\"\n",
    "    dossier = Path(dossier_images)\n",
    "    \n",
    "    if not dossier.exists():\n",
    "        print(f\"âŒ Dossier non trouvÃ©: {dossier}\")\n",
    "        return\n",
    "    \n",
    "    # Trouver toutes les images\n",
    "    extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
    "    images = []\n",
    "    for ext in extensions:\n",
    "        images.extend(dossier.glob(ext))\n",
    "        images.extend(dossier.glob(ext.upper()))\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(f\"âš ï¸ Aucune image trouvÃ©e dans {dossier}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“ {len(images)} image(s) trouvÃ©e(s)\")\n",
    "    print(\"Traitement en cours...\\n\")\n",
    "    \n",
    "    # Dossier de sortie\n",
    "    if sauvegarder:\n",
    "        dossier_sortie = dossier / 'resultats'\n",
    "        dossier_sortie.mkdir(exist_ok=True)\n",
    "    \n",
    "    resultats_globaux = []\n",
    "    \n",
    "    for i, image_path in enumerate(images, 1):\n",
    "        print(f\"[{i}/{len(images)}] {image_path.name}\")\n",
    "        \n",
    "        # DÃ©tecter\n",
    "        image_resultat, detections = detecter_et_classifier(\n",
    "            image_path, modele, CONFIG['confiance']\n",
    "        )\n",
    "        \n",
    "        if image_resultat is not None:\n",
    "            # Statistiques\n",
    "            nb_vides = sum(1 for d in detections if d['etat'] == 'vide')\n",
    "            nb_pleines = sum(1 for d in detections if d['etat'] == 'plein')\n",
    "            \n",
    "            print(f\"  â†’ {len(detections)} poubelle(s): {nb_vides} vide(s), {nb_pleines} pleine(s)\")\n",
    "            \n",
    "            resultats_globaux.append({\n",
    "                'image': image_path.name,\n",
    "                'total': len(detections),\n",
    "                'vides': nb_vides,\n",
    "                'pleines': nb_pleines\n",
    "            })\n",
    "            \n",
    "            # Sauvegarder\n",
    "            if sauvegarder:\n",
    "                sortie_path = dossier_sortie / image_path.name\n",
    "                image_bgr = cv2.cvtColor(image_resultat, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(str(sortie_path), image_bgr)\n",
    "    \n",
    "    # RÃ©sumÃ©\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“Š RÃ‰SUMÃ‰ GLOBAL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df = pd.DataFrame(resultats_globaux)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Total poubelles dÃ©tectÃ©es: {df['total'].sum()}\")\n",
    "    print(f\"Total vides: {df['vides'].sum()}\")\n",
    "    print(f\"Total pleines: {df['pleines'].sum()}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if sauvegarder:\n",
    "        print(f\"\\nâœ“ RÃ©sultats sauvegardÃ©s dans: {dossier_sortie}\")\n",
    "        \n",
    "        # Sauvegarder le CSV\n",
    "        csv_path = dossier_sortie / 'resultats.csv'\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"âœ“ Statistiques sauvegardÃ©es: {csv_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# modele = charger_modele_entraine()\n",
    "# resultats = detecter_dossier('chemin/vers/dossier_images', modele)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dbe1d7",
   "metadata": {},
   "source": [
    "## 10. Instructions d'Utilisation\n",
    "\n",
    "### ğŸ“‹ Ã‰tapes pour utiliser ce notebook :\n",
    "\n",
    "#### 1. **TÃ©lÃ©charger le dataset depuis Roboflow** :\n",
    "   - ExÃ©cutez la cellule 2 pour tÃ©lÃ©charger automatiquement\n",
    "   - Le dataset sera tÃ©lÃ©chargÃ© au format YOLOv9 (compatible YOLOv8)\n",
    "   - Les chemins seront configurÃ©s automatiquement\n",
    "\n",
    "#### 2. **VÃ©rifier le dataset** :\n",
    "   - ExÃ©cutez la cellule 4 pour vÃ©rifier que tout est OK\n",
    "   - VÃ©rifiez le nombre d'images dans chaque split\n",
    "\n",
    "#### 3. **EntraÃ®ner YOLO** :\n",
    "   ```python\n",
    "   modele = entrainer_yolo()\n",
    "   ```\n",
    "\n",
    "#### 4. **Utiliser le modÃ¨le** :\n",
    "   ```python\n",
    "   # Charger le modÃ¨le\n",
    "   modele = charger_modele_entraine()\n",
    "   \n",
    "   # Une image\n",
    "   image, detections = detecter_et_classifier('image.jpg', modele)\n",
    "   afficher_resultats(image, detections)\n",
    "   \n",
    "   # Un dossier\n",
    "   detecter_dossier('dossier_images/', modele)\n",
    "   \n",
    "   # Webcam\n",
    "   detecter_video(0, modele)\n",
    "   ```\n",
    "\n",
    "### ğŸ¯ Avantages de cette approche :\n",
    "\n",
    "âœ… **Dataset automatique** : TÃ©lÃ©chargement depuis Roboflow en 1 clic\n",
    "âœ… **DÃ©jÃ  annotÃ©** : Annotations YOLO incluses\n",
    "âœ… **PrÃªt Ã  l'emploi** : Configuration automatique\n",
    "âœ… **YOLO seul** : DÃ©tection + classification en une passe\n",
    "âœ… **Simple** : Moins de code, plus d'efficacitÃ©\n",
    "\n",
    "### ğŸ“Š Classes dÃ©tectÃ©es par votre modÃ¨le Roboflow :\n",
    "Les classes seront automatiquement dÃ©tectÃ©es depuis le fichier data.yaml\n",
    "\n",
    "### ğŸ’¡ Conseils :\n",
    "- VÃ©rifiez votre dataset aprÃ¨s tÃ©lÃ©chargement\n",
    "- Ajustez les hyperparamÃ¨tres selon vos besoins\n",
    "- Utilisez un GPU pour l'entraÃ®nement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec598d59",
   "metadata": {},
   "source": [
    "## âœ… RÃ©sumÃ©\n",
    "\n",
    "Ce notebook implÃ©mente un systÃ¨me complet de dÃ©tection et classification de poubelles avec **YOLO + Roboflow** :\n",
    "\n",
    "### ğŸ¯ Architecture :\n",
    "- **Roboflow** : Gestion et tÃ©lÃ©chargement automatique du dataset\n",
    "- **YOLOv8** : DÃ©tection ET classification en une seule Ã©tape\n",
    "\n",
    "### âš¡ Workflow simplifiÃ© :\n",
    "1. **TÃ©lÃ©charger** le dataset depuis Roboflow (1 ligne de code)\n",
    "2. **EntraÃ®ner** YOLOv8 sur vos donnÃ©es\n",
    "3. **Utiliser** le modÃ¨le pour dÃ©tecter et classifier\n",
    "\n",
    "### ğŸŒŸ Avantages :\n",
    "- âœ… Dataset professionnel depuis Roboflow\n",
    "- âœ… Annotations automatiques incluses\n",
    "- âœ… Configuration automatique\n",
    "- âœ… YOLO fait tout en une seule Ã©tape\n",
    "- âœ… Code simplifiÃ© et optimisÃ©\n",
    "\n",
    "### ğŸ“ Fonctions principales (en franÃ§ais) :\n",
    "- `telecharger_dataset_roboflow()` - TÃ©lÃ©charge depuis Roboflow\n",
    "- `verifier_dataset()` - VÃ©rifie le dataset\n",
    "- `entrainer_yolo()` - EntraÃ®ne le modÃ¨le\n",
    "- `detecter_et_classifier()` - DÃ©tecte et classifie\n",
    "- `detecter_video()` - Traite des vidÃ©os\n",
    "- `detecter_dossier()` - Batch processing\n",
    "\n",
    "### ğŸ¨ RÃ©sultats :\n",
    "Les couleurs dÃ©pendront des classes de votre dataset Roboflow.\n",
    "\n",
    "Bon entraÃ®nement ! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
